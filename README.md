# Gemini Cursor ✨

A second AI cursor 🖱️ for your desktop that can see your screen, hear you speak, and talk to you.

Powered by Google's Gemini 2.0 Flash (Experimental) model, the Multimodal Live API, Pointing, and Function calling capabilities.

Created by [@13point5](https://x.com/27upon2).

## Features

- 🖱️ Second AI cursor on your desktop
- 🚀 Multimodality: The model can see 📸, hear 🎤, and speak 🔊
- ⚡️ Real-time with low latency
- 🌐 Cross-platform support

## Tech Stack

- Frontend: Electron, React, TypeScript, Vite
- AI: Google Gemini API

## Prerequisites

- Node.js (v16 or higher)
- npm or yarn
- [Gemini API key](https://aistudio.google.com/apikey)

## Acknowledgements

- A lot of code from the Gemini [Multimodal Live API Web console](https://github.com/google-gemini/multimodal-live-api-web-console)
- Built using Google's [Multimodal Live API](https://ai.google.dev/gemini-api/docs/multimodal-live)
